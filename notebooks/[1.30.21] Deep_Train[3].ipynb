{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from src.models.conv_model import build_model as build_conv_model\n",
    "import tensorflow as tf\n",
    "from src.evaluator.evaluator import Evaluator\n",
    "from src.models.conv_model import correlation_coefficient_loss, pearson_r\n",
    "import math\n",
    "from src.data_loader.RNASeqLoader import RNASeqDataGenerator \n",
    "dependencies = {\n",
    "    'correlation_coefficient_loss': correlation_coefficient_loss,\n",
    "    'pearson_r': pearson_r\n",
    "}\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = RNASeqDataGenerator(\"data/processed/cDNA-ABE/train_data.hdf5\", 512, n_around_center=25)\n",
    "validation_generator = RNASeqDataGenerator(\"data/processed/cDNA-ABE/validation_data.hdf5\", 512, n_around_center=25)\n",
    "\n",
    "#model = tf.keras.models.load_model('models/cDNA-ABE/logs_nostruct/model_ckpt/1611875098.0045986.h5', custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Dropout, Flatten, BatchNormalization, MaxPool1D, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_model(dropout):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(51,4)))\n",
    "    model.add(Conv1D(filters=128, kernel_size=32, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv1D(filters=128, kernel_size=32, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv1D(filters=128, kernel_size=32, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv1D(filters=128, kernel_size=32, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv1D(filters=64, kernel_size=32, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv1D(filters=64, kernel_size=32, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv1D(filters=32, kernel_size=16, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv1D(filters=32, kernel_size=16, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv1D(filters=32, kernel_size=16, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = tf.keras.optimizers.RMSprop(decay=0.0005)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_crossentropy', 'mse', correlation_coefficient_loss, pearson_r])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = custom_model(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 51, 128)           16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 51, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 51, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 51, 128)           524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 51, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 51, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 51, 128)           524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 51, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 51, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 51, 128)           524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 51, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 51, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 51, 64)            262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 51, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 51, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 51, 64)            131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 51, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 51, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 51, 32)            32800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 51, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 51, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 51, 32)            16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 51, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 51, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 51, 32)            16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 51, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 51, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1632)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                26128     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,077,825\n",
      "Trainable params: 2,076,353\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "3568/5276 [===================>..........] - ETA: 4:15 - loss: 0.0666 - binary_crossentropy: 0.0666 - mean_squared_error: 0.0013 - correlation_coefficient_loss: 0.8927 - pearson_r: 0.3025"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "checkpoint_filepath = \"models/cDNA-ABE/2.10.21/model-{epoch:02d}-{val_loss:.4f}.h5\"\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    #monitor='val_pearson_r',\n",
    "    #mode='max',\n",
    "    save_best_only=False)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
    "                              patience=4, min_lr=0.00001)\n",
    "\n",
    "history = model.fit(x=train_generator, epochs=10, validation_data=validation_generator, callbacks=[model_checkpoint_callback], use_multiprocessing=True, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.15.2]",
   "language": "python",
   "name": "conda-env-tf1.15.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
